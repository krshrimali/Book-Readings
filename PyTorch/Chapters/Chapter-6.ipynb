{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Sequence Data and Text\n",
    "\n",
    "1. Preprocessing Text: Tokenization, Vectorization and n-gram representation\n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n",
    "6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points**\n",
    "\n",
    "* Text is a type of Sequential Data.\n",
    "* DL Sequential Models (RNNs, LSTMs), can find patterns in Sequential Data and Text:\n",
    "    * Natural Language Understanding\n",
    "    * Document Classification\n",
    "    * Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing text\n",
    "\n",
    "1. Convert text to tokens (words/characters). (**Tokenization**)\n",
    "    * Example: **Input text** - \"I am studying PyTorch\". **Tokens** will be - \"I\", \"am\", \"studying\", \"PyTorch\"\n",
    "2. Map each token to a vector. (**Vectorization**) There are two techniques for Vectorization\n",
    "    * One-hot encoding\n",
    "    * Word embedding\n",
    "    \n",
    "Let's do this in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "import torch, torchvision\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "I'll try and convert a quote from one of the most famous scientist, politician: Late Indian President, Dr. APJ Abdul Kalam.\n",
    "\n",
    "\"Never stop fighting until you arrive at your destined place – that is, the unique you. Have an aim in life, continuously acquire knowledge, work hard, and have the perseverance to realize the great life.\"\n",
    "\n",
    "Libraries for Tokenization: spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Never stop fighting until you arrive at your destined place – that is, the unique you. Have an aim in life, continuously acquire knowledge, work hard, and have the perseverance to realize the great life.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_words = text.split(\" \") # use a space as delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Never', 'stop', 'fighting', 'until']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting 4 tokens - converting text to words\n",
    "tokens_words[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text to characters\n",
    "tokens_char = list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'e', 'v', 'e']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting 4 tokens - characters\n",
    "tokens_char[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Representations\n",
    "\n",
    "Challenge - Loses sequential nature of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_grams = list(ngrams(text.split(), 2)) # 2 - number of words to grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Never', 'stop'), ('stop', 'fighting'), ('fighting', 'until'), ('until', 'you')]"
     ]
    }
   ],
   "source": [
    "print(two_grams[:4], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "1. One Hot Encoding\n",
    "2. Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each token is represented by a vector of length N\n",
    "# N - vocab size \n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        self.length = 0\n",
    "    def add_word(self, word):\n",
    "        if word not in self.idx2word:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = self.length + 1\n",
    "            self.length += 1\n",
    "        return self.word2idx[word]\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "    def onehot_encoded(self, word):\n",
    "        vec = np.zeros(self.length)\n",
    "        vec[self.word2idx[word]] = 1\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = Dictionary()\n",
    "for token in text.split(' '):\n",
    "    dic.add_word(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Never': 1, 'stop': 2, 'fighting': 3, 'until': 4, 'you': 5, 'arrive': 6, 'at': 7, 'your': 8, 'destined': 9, 'place': 10, '–': 11, 'that': 12, 'is,': 13, 'the': 14, 'unique': 15, 'you.': 16, 'Have': 17, 'an': 18, 'aim': 19, 'in': 20, 'life,': 21, 'continuously': 22, 'acquire': 23, 'knowledge,': 24, 'work': 25, 'hard,': 26, 'and': 27, 'have': 28, 'perseverance': 29, 'to': 30, 'realize': 31, 'great': 32, 'life.': 33}\n"
     ]
    }
   ],
   "source": [
    "print(dic.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.onehot_encoded('Never')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.onehot_encoded('fighting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disadvantages**:\n",
    "\n",
    "1. Too sparse (too many zeros)\n",
    "2. Size of vector very large, if size of the text increases. (Therefore not generally used in DL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantically closer words - have similar representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class:** `data.Field`\n",
    "\n",
    "Attributes:\n",
    "\n",
    "1. `sequential`:\n",
    "```python\n",
    "if(True):\n",
    "    # apply tokenization\n",
    "else:\n",
    "    # don't apply tokenization\n",
    "```\n",
    "2. `use_vocab`:\n",
    "```python\n",
    "if(True):\n",
    "    # use a vocab object\n",
    "else:\n",
    "    # data should be already numerical.\n",
    "```\n",
    "Similarly, find others in the docs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Field in module torchtext.data.field:\n",
      "\n",
      "class Field(RawField)\n",
      " |  Defines a datatype together with instructions for converting to Tensor.\n",
      " |  \n",
      " |  Field class models common text processing datatypes that can be represented\n",
      " |  by tensors.  It holds a Vocab object that defines the set of possible values\n",
      " |  for elements of the field and their corresponding numerical representations.\n",
      " |  The Field object also holds other parameters relating to how a datatype\n",
      " |  should be numericalized, such as a tokenization method and the kind of\n",
      " |  Tensor that should be produced.\n",
      " |  \n",
      " |  If a Field is shared between two columns in a dataset (e.g., question and\n",
      " |  answer in a QA dataset), then they will have a shared vocabulary.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      sequential: Whether the datatype represents sequential data. If False,\n",
      " |          no tokenization is applied. Default: True.\n",
      " |      use_vocab: Whether to use a Vocab object. If False, the data in this\n",
      " |          field should already be numerical. Default: True.\n",
      " |      init_token: A token that will be prepended to every example using this\n",
      " |          field, or None for no initial token. Default: None.\n",
      " |      eos_token: A token that will be appended to every example using this\n",
      " |          field, or None for no end-of-sentence token. Default: None.\n",
      " |      fix_length: A fixed length that all examples using this field will be\n",
      " |          padded to, or None for flexible sequence lengths. Default: None.\n",
      " |      dtype: The torch.dtype class that represents a batch of examples\n",
      " |          of this kind of data. Default: torch.long.\n",
      " |      preprocessing: The Pipeline that will be applied to examples\n",
      " |          using this field after tokenizing but before numericalizing. Many\n",
      " |          Datasets replace this attribute with a custom preprocessor.\n",
      " |          Default: None.\n",
      " |      postprocessing: A Pipeline that will be applied to examples using\n",
      " |          this field after numericalizing but before the numbers are turned\n",
      " |          into a Tensor. The pipeline function takes the batch as a list, and\n",
      " |          the field's Vocab.\n",
      " |          Default: None.\n",
      " |      lower: Whether to lowercase the text in this field. Default: False.\n",
      " |      tokenize: The function used to tokenize strings using this field into\n",
      " |          sequential examples. If \"spacy\", the SpaCy English tokenizer is\n",
      " |          used. Default: str.split.\n",
      " |      include_lengths: Whether to return a tuple of a padded minibatch and\n",
      " |          a list containing the lengths of each examples, or just a padded\n",
      " |          minibatch. Default: False.\n",
      " |      batch_first: Whether to produce tensors with the batch dimension first.\n",
      " |          Default: False.\n",
      " |      pad_token: The string token used as padding. Default: \"<pad>\".\n",
      " |      unk_token: The string token used to represent OOV words. Default: \"<unk>\".\n",
      " |      pad_first: Do the padding of the sequence at the beginning. Default: False.\n",
      " |      truncate_first: Do the truncating of the sequence at the beginning. Default: False\n",
      " |      stop_words: Tokens to discard during the preprocessing step. Default: None\n",
      " |      is_target: Whether this field is a target variable.\n",
      " |          Affects iteration over batches. Default: False\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Field\n",
      " |      RawField\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sequential=True, use_vocab=True, init_token=None, eos_token=None, fix_length=None, dtype=torch.int64, preprocessing=None, postprocessing=None, lower=False, tokenize=<function Field.<lambda> at 0x7f81a4e536a8>, include_lengths=False, batch_first=False, pad_token='<pad>', unk_token='<unk>', pad_first=False, truncate_first=False, stop_words=None, is_target=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  build_vocab(self, *args, **kwargs)\n",
      " |      Construct the Vocab object for this field from one or more datasets.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          Positional arguments: Dataset objects or other iterable data\n",
      " |              sources from which to construct the Vocab object that\n",
      " |              represents the set of possible values for this field. If\n",
      " |              a Dataset object is provided, all columns corresponding\n",
      " |              to this field are used; individual columns can also be\n",
      " |              provided directly.\n",
      " |          Remaining keyword arguments: Passed to the constructor of Vocab.\n",
      " |  \n",
      " |  numericalize(self, arr, device=None)\n",
      " |      Turn a batch of examples that use this field into a Variable.\n",
      " |      \n",
      " |      If the field has include_lengths=True, a tensor of lengths will be\n",
      " |      included in the return value.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          arr (List[List[str]], or tuple of (List[List[str]], List[int])):\n",
      " |              List of tokenized and padded examples, or tuple of List of\n",
      " |              tokenized and padded examples and List of lengths of each\n",
      " |              example if self.include_lengths is True.\n",
      " |          device (str or torch.device): A string or instance of `torch.device`\n",
      " |              specifying which device the Variables are going to be created on.\n",
      " |              If left as default, the tensors will be created on cpu. Default: None.\n",
      " |  \n",
      " |  pad(self, minibatch)\n",
      " |      Pad a batch of examples using this field.\n",
      " |      \n",
      " |      Pads to self.fix_length if provided, otherwise pads to the length of\n",
      " |      the longest example in the batch. Prepends self.init_token and appends\n",
      " |      self.eos_token if those attributes are not None. Returns a tuple of the\n",
      " |      padded list and a list containing lengths of each example if\n",
      " |      `self.include_lengths` is `True` and `self.sequential` is `True`, else just\n",
      " |      returns the padded list. If `self.sequential` is `False`, no padding is applied.\n",
      " |  \n",
      " |  preprocess(self, x)\n",
      " |      Load a single example using this field, tokenizing if necessary.\n",
      " |      \n",
      " |      If the input is a Python 2 `str`, it will be converted to Unicode\n",
      " |      first. If `sequential=True`, it will be tokenized. Then the input\n",
      " |      will be optionally lowercased and passed to the user-provided\n",
      " |      `preprocessing` Pipeline.\n",
      " |  \n",
      " |  process(self, batch, device=None)\n",
      " |      Process a list of examples to create a torch.Tensor.\n",
      " |      \n",
      " |      Pad, numericalize, and postprocess a batch and create a tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch (list(object)): A list of object from a batch of examples.\n",
      " |      Returns:\n",
      " |          torch.autograd.Variable: Processed object given the input\n",
      " |          and custom postprocessing Pipeline.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  dtypes = {torch.float32: <class 'float'>, torch.float64: <class 'float...\n",
      " |  \n",
      " |  vocab_cls = <class 'torchtext.vocab.Vocab'>\n",
      " |      Defines a vocabulary object that will be used to numericalize a field.\n",
      " |      \n",
      " |      Attributes:\n",
      " |          freqs: A collections.Counter object holding the frequencies of tokens\n",
      " |              in the data used to build the Vocab.\n",
      " |          stoi: A collections.defaultdict instance mapping token strings to\n",
      " |              numerical identifiers.\n",
      " |          itos: A list of token strings indexed by their numerical identifiers.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RawField:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(data.Field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, batch_first=True, fix_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:23<00:00, 3.59MB/s]\n"
     ]
    }
   ],
   "source": [
    "# downloading datasets\n",
    "train, text = torchtext.datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of train.fields:  <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Datatype of train.fields: \", type(train.fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['elvira', 'mistress', 'of', 'the', 'dark', 'is', 'one', 'of', 'my', 'fav', 'movies,', 'it', 'has', 'every', 'thing', 'you', 'would', 'want', 'in', 'a', 'film,', 'like', 'great', 'one', 'liners,', 'sexy', 'star', 'and', 'a', 'outrageous', 'story!', 'if', 'you', 'have', 'not', 'seen', 'it,', 'you', 'are', 'missing', 'out', 'on', 'one', 'of', 'the', 'greatest', 'films', 'made.', 'i', \"can't\", 'wait', 'till', 'her', 'new', 'movie', 'comes', 'out!'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kushashwa/Pictures/\"\n",
    "files = glob.glob(os.path.join(path, '[k | K]*[.jpg | .png]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kushashwa/Pictures/kush_contours.png'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[3] # 4th image is kush_contours.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = np.random.permutation(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kushashwa/Pictures/kush_contours.png'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clearly second image is kush_contours.png now.\n",
    "shuffle[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kushashwa/Pictures/kush_contours.png kush_contours\n"
     ]
    }
   ],
   "source": [
    "for t in shuffle[1:2]:\n",
    "    folder = t.split('/')[-1].split('.')[0]\n",
    "    print(t, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Pre-processing Image Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Resize all the images to the same size. Most of the deep learning architectures\n",
    "expect the images to be of the same size.\n",
    "2. Normalize the dataset with the mean and standard deviation of the dataset.\n",
    "3. Convert the image dataset to a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "simple_transform = transforms.Compose([transforms.Scale((224, 224)), \n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize([0.485, 0.456,\n",
    "                                        0.406], [0.229, \\\n",
    "                                                0.224, 0.225])])\n",
    "train = ImageFolder('/home/kushashwa/Pictures/', simple_transform)\n",
    "valid = ImageFolder('/home/kushashwa/Pictures/', simple_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 1565\n",
       "    Root Location: /home/kushashwa/Pictures/\n",
       "    Transforms (if any): Compose(\n",
       "                             Scale(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 1565\n",
       "    Root Location: /home/kushashwa/Pictures/\n",
       "    Transforms (if any): Compose(\n",
       "                             Scale(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Camera': 0,\n",
       " 'Club': 1,\n",
       " 'DCIM': 2,\n",
       " 'Good_Thoughts': 3,\n",
       " 'Pictures': 4,\n",
       " 'Presentation': 5,\n",
       " 'Wallpapers': 6,\n",
       " 'Webcam': 7,\n",
       " 'WhatsApp': 8,\n",
       " 'cust_im': 9,\n",
       " 'screenshots': 10}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Camera',\n",
       " 'Club',\n",
       " 'DCIM',\n",
       " 'Good_Thoughts',\n",
       " 'Pictures',\n",
       " 'Presentation',\n",
       " 'Wallpapers',\n",
       " 'Webcam',\n",
       " 'WhatsApp',\n",
       " 'cust_im',\n",
       " 'screenshots']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def imshow(inpTensor):\n",
    "    '''\n",
    "    visualizes tensor\n",
    "    '''\n",
    "    inp = inpTensor.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(inp)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std*inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
